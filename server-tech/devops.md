# DevOps

## 什么叫DevOps?

DevOps（英文Development和Operations的组合）是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、运维和质量保障（QA）部门之间的沟通、协作与整合。它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运维工作必须紧密合作。

这是一个比较书面理论化的对于DevOps的定义(来自于百度百科)。其实通俗来说，DevOps就是融合开发、运维以及QA，更好地协同工作。

通常的一个流程，一个开发工程师开发完成一个系统，测试交给QA，然后部署的任务交给运维工程师来做。这样会有一个显而易见的问题。由于要经受多个人，那么任何一个中间人都会成为瓶颈从而影响整个流程。如果系统采用了新的技术而运维却没接触过，也很容易造成发布的不顺利或者失败。

先抛开QA不谈，其中的两个关键角色就是开发和运维，为什么是这两个角色呢？因为典型的价值流就是位于业务（定义需求）和客户（交付价值）之间。

这两者的矛盾促使了DevOps概念的提出。DevOps不仅仅是一种软件的部署方法。它通过一种全新的方式，来思考如何让软件的作者（开发部门）和运营者（运营部门）进行合作与协同。使用了DevOps模型之后，会使两个部门更好的交互，使两者的关系得到改善，从而让很多领域从中受益，例如：自动化、监视、能力规划和性能、备份与恢复、安全、网络以及服务提供（provisioning）等等。

## 开发在DevOps中的角色

在DevOps中开发扮演的角色仍然是最关键的。但一般意义上一个系统的整个流程仍需要运维的大量参与。而我所理解的或者说我认为更好的一种方式就是开发能够兼职运维的角色，承担一部分部署责任，这样能够更好地保证系统的部署和发布。所以，在这一点上开发应该具有运维的一部分技能，能够承担一部分运维的责任。

## DevOps工具

上面说到开发应该具有一部分运维技能，那么哪些运维技能需要开发人员掌握呢？这里从运维角度罗列一些常用“武器”。

### 1. CDN

你有个web服务，部署在了北京的机房，那么北京的用户访问速度肯定是大于其他区域的用户的。那么对于一些高频率访问且要求实时性比较高的内容，如何提高其他地域的用户的访问速度呢？很容易想到的一个办法就是在每个地域都部署一个服务然后服务之间以某种机制进行同步。这就是CDN，全称是内容分布式网络。

对于一般的中小型公司来说，都是租用大的cdn供应商的服务的。除非你特别有钱，能够在全国各个地方都部署自己的服务器，然后构建自己的CDN。

### 2. 负载均衡

负载均衡在服务端领域中是一个很关键的技术。可以分为以下两种。

- 硬件负载均衡
- 软件负载均衡

其中，硬件负载均衡的性能无疑是最优的，其中以F5为代表。但是，与高性能并存的是其成本的昂贵。所以对于很多初创公司来说，一般是选用软件负载均衡的方案。

软件负载均衡中又可以分为四层负载均衡和七层负载均衡。四层负载均衡指的是tcp层，代表的软件为lvs，此软件的创始人为章文嵩博士（就职于阿里），是全世界使用最多的软件负载均衡软件。七层负载均衡的代表则是nginx，是反向代理服务器的一种典型应用。此外，HaProxy兼具四层和七层负载均衡的功能，也是一种很强大的负载均衡软件。

对于LVS，其分为三种模式：

- NAT: 修改数据包destination ip，in和out都要经过lvs。
- DR：修改数据包mac地址，lvs和realserver需要在一个vlan。
- IP TUUNEL：修改数据包destination ip和源ip，realserver需要支持ip tunnel协议。lvs和realserver不需要在一个vlan。

三种模式各有优缺点，目前还有阿里开源的一个FULL NAT是在NAT原来的DNAT上加入了SNAT的功能。

对于Nginx,其本来的功能是一个Web服务器，类似的还有apche httpserver，他们都具有反向代理的功能，基于此功能，便可以提供负载均衡的功能。ngixn的特殊设计，使其可以抗住很高的并发（24G内存可以抗住200万并发）。对于其的优化配置可见附录10.2中相关段落。

阿里开源的tengine是其在nginx开源版本上的做的二次开发，基本涵盖了nginx的收费版本的一些高级功能。比如加入的upstream主动健康检查弥补了nginx在负载均衡方面的不足，使得nginx在lb上变得更加强大。想要深入了解的可以访问<http://tengine.taobao.org/>。

### 3. 应用服务器

目前比较常用的web服务器包括

- Apache http server

    此服务器一般用于在lamp架构中，主要是运行php程序的。当然，现在的php服务有向lnmp转化的趋势。

- Tomcat

    此服务器是典型的java应用服务器，基本上是java后端应用最常用的应用服务器。对于其的优化配置可见附录10.2中相关段落。

- IIS

    此服务器是c#、asp等win系列服务的应用服务器。性能实在不敢恭维。一般来说在传统it行业占有率比较高。

### 4. 数据库

#### mysql

mysql是目前最常用的关系型数据库，支持复杂的查询。但是其负载能力一般，很多时候一个系统的瓶颈就发生在mysql这一点，当然有时候也和sql语句的效率有关。比如，牵扯到联表的查询一般说来效率是不会太高的。

影响数据库性能的因素一般有以下几点：

- 硬件配置：这个无需多说
- 数据库设置：max_connection的一些配置会影响数据库的连接数
- 数据表的设计：使用冗余字段避免联表查询；使用索引提高查询效率
- 查询语句是否合理：这个牵扯到的是个人的编码素质。比如，查询符合某个条件的记录，我见过有人把记录全部查出来，再去逐条对比
- 引擎的选择：myisam和innodb两者的适用场景不同，不存在绝对的优劣

抛开以上因素，当数据量单表突破千万甚至百万时（和具体的数据有关），需要对mysql数据库进行优化，一种常见的方案就是分表：
- 垂直分表：在列维度的拆分
- 水平分表：行维度的拆分

此外，对于数据库，可以使用读写分离的方式提高性能，尤其是对那种读频率远大于写频率的业务场景。这里采用master/slave的方式实现读写分离，前面用程序控制或者加一个proxy层。可以选择使用MySQL Proxy，编写lua脚本来实现基于proxy的mysql读写分离。

现在很多大的公司对这些分表、主从分离、分布式都基于mysql做了自己的二次开发，形成了自己公司的一套分布式数据库系统。比如阿里的TDDL。

#### redis

当然，对于系统中并发很高并且访问很频繁的数据，关系型数据库还是不能妥妥应对。这时候就需要缓存数据库出马以隔离对mysql的访问,防止mysql崩溃
。
其中，redis是目前用的比较多的缓存数据库（当然，也有直接把redis当做数据库使用的）。redis是单线程基于内存的数据库，读写性能远远超过mysql。一般情况下，对redis做读写分离主从同步就可以应对大部分场景的应用。但是这样的方案缺少ha，尤其对于分布式应用，是不可接受的。目前，redis集群的实现方案有以下几个：

- redis cluster:这是一种去中心化的方案，是redis的官方实现。是一种非常“重”的方案，已经不是Redis单实例的“简单、可依赖”了。目前应用案例还很少，貌似国内的芒果台用了，结局不知道如何。
- [twemproxy](https://github.com/twitter/twemproxy)：这是twitter开源的redis和memcached的proxy方案。比较成熟，目前的应用案例比较多，但也有一些缺陷，尤其在运维方面。比如无法平滑的扩容/缩容，运维不友好等。
- [codis](https://github.com/wandoulabs/codis): 这个是豌豆荚开源的redis proxy方案，能够兼容twemproxy，并且对其做了很多改进。由豌豆荚于2014年11月开源，基于Go和C开发。现已广泛用于豌豆荚的各种Redis业务场景。现在比Twemproxy快近100%。目前据我所知除了豌豆荚之外，hulu、网易等公司也在使用这套方案。当然，其升级项目[https://github.com/reborndb/reborn](reborndb)号称比codis还要厉害。

### 5. Linux性能优化与诊断

由于现在大多数互联网应用都是部署在Linux上的，因此对于Linux系统的优化以及故障诊断是一个很关键的技能。

## SRE

最近听说了一个SRE的名词，指的是Site Reliable Engineering(网站可用性工程)。这个词起源于Google，是运维更进一层的一个角色，一般是由软件研发工程师转型而来的。

在Google的SRE工程师一般需要掌握:算法，数据结构，编程能力，网络编程，分布式系统，可扩展架构，故障排除。比起国内的OPS要求要高得多，一般由软件研发工程师转型而来。
